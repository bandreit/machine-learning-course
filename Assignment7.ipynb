{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn import (datasets, decomposition, ensemble, \n",
    "                     metrics, model_selection, preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the body points using mediapipe model.\n",
    "def mediapipe_detection(image, holistic,hands):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR to RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    holistic_model = holistic.process(image)                 # Make prediction\n",
    "    hands_model = hands.process(image)\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    \n",
    "    resize_up = cv2.resize(image, (1024,800), interpolation= cv2.INTER_AREA)\n",
    "\n",
    "    return resize_up, holistic_model,hands_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, pose,hands):\n",
    "    if(pose.pose_world_landmarks):\n",
    "        mp_drawing.draw_landmarks(image, pose.pose_world_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "            # Draw pose connections\n",
    "        mp_drawing.draw_landmarks(image, pose.pose_world_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    if hands.multi_hand_landmarks:\n",
    "        for hand_landmarks in hands.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS) # Draw hands\n",
    "                # Draw right hand connections  \n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pose_world_to_array(hollistic):\n",
    "    landmarks = hollistic.pose_world_landmarks\n",
    "    data = []\n",
    "    \n",
    "    if(landmarks == None):\n",
    "        return None\n",
    "    else:\n",
    "        landmarks = landmarks.landmark[11:23]\n",
    "        for item in landmarks:\n",
    "            if(item==None):\n",
    "                data.append(None)\n",
    "            else:\n",
    "                landmark = {'X':item.x,'Y':item.y}\n",
    "                data.append(landmark)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_left_and_right_hand_landmarks( hands):\n",
    "    hands_position = hands.multi_handedness\n",
    "    hands_landmarks = hands.multi_hand_world_landmarks\n",
    "    \n",
    "    if not hands_position:\n",
    "        return [None, None]\n",
    "        \n",
    "    second_hand=None\n",
    "\n",
    "    first_hand = hands_position[0].classification[0]\n",
    "    if(len(hands_position) == 2):\n",
    "        second_hand = hands_position[1].classification[0]\n",
    "\n",
    "    if len(hands_position) == 1 or (second_hand and first_hand.label == second_hand.label):\n",
    "        if(len(hands_position) == 2 and first_hand.score < second_hand.score):\n",
    "            landmarks = hands_landmarks[1].landmark\n",
    "        else:\n",
    "            landmarks = hands_landmarks[0].landmark\n",
    "        hand = []\n",
    "        for item in landmarks:\n",
    "            hand.append({'X': item.x, 'Y': item.y, 'Z': item.z})\n",
    "\n",
    "        if hands_position[0].classification[0].label == 'Left':\n",
    "            return [None,hand]\n",
    "\n",
    "        return [hand,None]\n",
    "\n",
    "    left_hand = []\n",
    "    right_hand = []\n",
    "    left_hand_landmarks = hands_landmarks[0].landmark\n",
    "    right_hand_landmarks = hands_landmarks[1].landmark\n",
    "    for i in range(len(left_hand_landmarks)):\n",
    "        right_hand.append({'X': left_hand_landmarks[i].x, 'Y': left_hand_landmarks[i].y, 'Z': left_hand_landmarks[i].z})\n",
    "        left_hand.append({'X': right_hand_landmarks[i].x, 'Y': right_hand_landmarks[i].y, 'Z': right_hand_landmarks[i].z})\n",
    "\n",
    "    return [left_hand, right_hand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_json(\"Data.json\")\n",
    "# top_words = ['thank you','love','deaf',\"hello\",\"friend\"]\n",
    "\n",
    "# X_thank_you = data[data['label']==\"thank you\"]\n",
    "# X_love= data[data['label']==\"love\"]\n",
    "# X_deaf = data[data['label']==\"deaf\"]\n",
    "# X_hello = data[data['label']==\"hello\"]\n",
    "# X_friend = data[data['label']==\"friend\"]\n",
    "\n",
    "# data_type = {\"RIGHT_HAND_WORLD_LANDMARKS\": [], \"LEFT_HAND_WORLD_LANDMARKS\":[],\"POSE_WORLD_LANDMARKS\":[],\"Label\":[]}\n",
    "# X = np.concatenate((X_thank_you,X_love,X_deaf,X_hello,X_friend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder = \"C:/Users/ion/Desktop/WLASL ML PROCESSING/WLASL2000/WLASL2000/\"\n",
    "# index = 0\n",
    "# for item in X:\n",
    "#     print(item)\n",
    "#     print(Folder + str(item[1]).zfill(5) + \".mp4\")\n",
    "#     cap = cv2.VideoCapture(Folder + str(item[1]).zfill(5) + \".mp4\")\n",
    "#     right_hand = []\n",
    "#     left_hand = []\n",
    "#     pose_shape = []\n",
    "#     pose_world = []\n",
    "#     right_hand_world = []\n",
    "#     left_hand_world = []\n",
    "#     data_type[\"Label\"].append(item[0].lower())\n",
    "#     print(index)\n",
    "#     index = index+1\n",
    "#     with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "#         with mp_hands.Hands(min_detection_confidence=0.3,min_tracking_confidence=0.3) as hands:\n",
    "#             while(cap.isOpened()):\n",
    "#                 success, frame = cap.read()\n",
    "#                 if(not success):\n",
    "#                     break\n",
    "#                 if(success):\n",
    "#                     frame.flags.writeable = False\n",
    "#                     image,hollistic,hands_position = mediapipe_detection(frame,pose,hands)\n",
    "#                     pose_world.append(convert_pose_world_to_array(hollistic))\n",
    "\n",
    "#                     hands_world_landmarks = get_left_and_right_hand_landmarks(hands_position)\n",
    "\n",
    "#                     left_hand_world.append(hands_world_landmarks[0])\n",
    "#                     right_hand_world.append(hands_world_landmarks[1])\n",
    "                    \n",
    "#     data_type[\"POSE_WORLD_LANDMARKS\"].append(pose_world)   \n",
    "#     data_type[\"LEFT_HAND_WORLD_LANDMARKS\"].append(left_hand_world)\n",
    "#     data_type[\"RIGHT_HAND_WORLD_LANDMARKS\"].append(right_hand_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame.from_dict(data_type)\n",
    "# df.to_json('5_words_data.json',orient='index')\n",
    "df = pd.read_json('5_words_data.json',orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_removed_index_from_world_landmarks(right_hand,left_hand):\n",
    "    removed_indexes = []\n",
    "    # print((right_hand)==None)\n",
    "    for i in range(len(right_hand)):\n",
    "        if(len(right_hand) - len(removed_indexes) <=60):\n",
    "            break\n",
    "        if(right_hand[i] == None and left_hand[i] == None):\n",
    "            removed_indexes.append(i)\n",
    "    return removed_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_60_frames(data):\n",
    "    for item in data.iterrows():\n",
    "        world_remove_indexes = get_removed_index_from_world_landmarks(item[1].RIGHT_HAND_WORLD_LANDMARKS,item[1].LEFT_HAND_WORLD_LANDMARKS)\n",
    "\n",
    "        if(len(item[1].RIGHT_HAND_WORLD_LANDMARKS)<60):\n",
    "            current_length = len(item[1].RIGHT_HAND_WORLD_LANDMARKS)\n",
    "            for i in range(current_length,60):\n",
    "                item[1].RIGHT_HAND_WORLD_LANDMARKS.append(None)\n",
    "                item[1].LEFT_HAND_WORLD_LANDMARKS.append(None)\n",
    "                item[1].POSE_WORLD_LANDMARKS.append(None)\n",
    "\n",
    "        \n",
    "        for index in sorted(world_remove_indexes, reverse=True):\n",
    "            del item[1].RIGHT_HAND_WORLD_LANDMARKS[index]\n",
    "            del item[1].LEFT_HAND_WORLD_LANDMARKS[index]\n",
    "            del item[1].POSE_WORLD_LANDMARKS[index]\n",
    "            \n",
    "        if(len(item[1].RIGHT_HAND_WORLD_LANDMARKS)>60):\n",
    "            del item[1].RIGHT_HAND_WORLD_LANDMARKS[60:]\n",
    "            del item[1].LEFT_HAND_WORLD_LANDMARKS[60:]\n",
    "            del item[1].POSE_WORLD_LANDMARKS[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "labels = []\n",
    "def extract_keypoints(pose_world_landmarks,right_hand_world_landmarks,left_hand_world_landmarks):\n",
    "    pose = np.array([[res['X'], res['Y']] for res in pose_world_landmarks]).flatten() if pose_world_landmarks[0] else np.zeros(12*2)\n",
    "    lh = np.array([[res['X'], res['Y'], res['Z']] for res in left_hand_world_landmarks ]).flatten() if left_hand_world_landmarks  else np.zeros(21*3)\n",
    "    rh = np.array([[res['X'], res['Y'], res['Z']] for res in right_hand_world_landmarks ]).flatten() if right_hand_world_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, lh, rh])\n",
    "\n",
    "def convert_world_to_2d_array(data):\n",
    "    k = 0\n",
    "    for item in data.iterrows():\n",
    "        sequence = []\n",
    "        labels.append(item[1].Label)\n",
    "        for i in range(len(item[1].RIGHT_HAND_WORLD_LANDMARKS)):    \n",
    "            pose_world = item[1].POSE_WORLD_LANDMARKS[i]\n",
    "            if pose_world == None:\n",
    "                pose_world = [None]\n",
    "            points = extract_keypoints(pose_world,item[1].RIGHT_HAND_WORLD_LANDMARKS[i],item[1].LEFT_HAND_WORLD_LANDMARKS[i])\n",
    "            sequence.append(points)\n",
    "        sequences.append(sequence)\n",
    "        k= k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_60_frames(df)\n",
    "convert_world_to_2d_array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.array(sequences,dtype=float)\n",
    "words = np.array(labels).reshape(-1,1)\n",
    "print(words)\n",
    "Y = OneHotEncoder().fit_transform(words).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seeds():\n",
    "   tf.random.set_seed(69)\n",
    "   np.random.seed(69)\n",
    "   random.seed(69)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test , y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=69,stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_random_seeds()\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# input layer\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu', input_shape=(60,150)))\n",
    "\n",
    "#hidden layers\n",
    "model.add(LSTM(256, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(256, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(128, return_sequences=False, activation='relu'))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(Y.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=430,batch_size=10,validation_split = 0.2,verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Learning curves\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(history.history['accuracy'], label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], label = 'valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on training data: {}\".format(model.evaluate(X_train, y_train)))\n",
    "print(\"Accuracy on test data: {}\".format(model.evaluate(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_reshaped= X.reshape(X.shape[0], (X.shape[1]*X.shape[2]))\n",
    "Y_reshaped = words.flatten()\n",
    "X_train, X_test , y_train, y_test = train_test_split(X_reshaped, Y_reshaped, test_size=0.2, random_state=69,stratify = Y_reshaped)\n",
    "\n",
    "parameters = {'n_neighbors':range(1,15,2),'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan'],\n",
    "               'algorithm':['ball_tree','kd_tree','brute']}\n",
    "\n",
    "# X_R.shape,words.shape\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(),parameters,cv=5,refit=True,return_train_score=True,verbose = 4)\n",
    "\n",
    "X_train_knn,X_test_knn,Y_train_knn,Y_test_knn = train_test_split(X_train,y_train,random_state= 69,stratify = y_train)\n",
    "\n",
    "grid_search.fit(X_train_knn,Y_train_knn)\n",
    "\n",
    "print(\"Best Parameter : {}\".format(grid_search.best_params_))\n",
    "print(\"Best Cross Validation Score : {}\".format(grid_search.best_score_))\n",
    "print(\"Best estimator : {}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Test Score : {}\".format(grid_search.score(X_test_knn,Y_test_knn)))\n",
    "knn = KNeighborsClassifier(algorithm= 'ball_tree', metric =  'manhattan', n_neighbors= 3, weights= 'distance')\n",
    "\n",
    "kNN_y_pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = np.array(['thank you', 'love', 'deaf', 'hello','friend'])\n",
    "actual = y_test\n",
    "predicted = kNN_y_pred\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['thank you', 'love', 'deaf', 'hello','friend'])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "Accuracy = metrics.accuracy_score(actual, predicted)\n",
    "Precision = metrics.precision_score(actual, predicted, average=\"weighted\")\n",
    "Sensitivity_recall = metrics.recall_score(actual, predicted, average=\"weighted\")\n",
    "F1_score = metrics.f1_score(actual, predicted, average=\"weighted\")\n",
    "\n",
    "print(\"Accuracy measures how often the model is correct: {}\".format(Accuracy))\n",
    "print(\"Precision measures percentage of true positive: {}\".format(Precision))\n",
    "print(\"Sensitivity is good at understanding how well the model predicts something is positive: {}\".format(Sensitivity_recall))\n",
    "print(\"F-score is the harmonic mean of precision and sensitivity. It considers both false positive and false negative cases: {}\".format(F1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    " \n",
    "parameters = {'n_estimators':range(100, 200, 10), 'criterion': ['gini','entropy'], 'max_features': ['log2', 'sqrt'], 'min_samples_leaf': range(5, 10), } \n",
    "grid_search = GridSearchCV(RandomForestClassifier(),parameters,cv=5,refit=True,return_train_score=True,verbose = 4, random_state=69) \n",
    "grid_search.fit(X_train,y_train) \n",
    " \n",
    "print(\"Best Parameter : {}\".format(grid_search.best_params_)) \n",
    "print(\"Best Cross Validation Score : {}\".format(grid_search.best_score_)) \n",
    "print(\"Best estimator : {}\".format(grid_search.best_estimator_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
